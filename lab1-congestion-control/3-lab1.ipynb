{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc402fb-9ec3-49db-89d3-a2d5e97a8b27",
   "metadata": {},
   "source": [
    "# Lab 1: TCP Congestion Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba384dab",
   "metadata": {},
   "source": [
    "We will go through this notebook together in class for our first lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fdbbd",
   "metadata": {},
   "source": [
    "In this lab, you will:\n",
    "\n",
    "- Review the basic operation of TCP congestion control\n",
    "- Run TCP flows with different congestion control algorithms and visualize the results\n",
    "- Explore how different congestion control algorithms interact with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aec0d3-4707-4214-b999-c894eec7753c",
   "metadata": {},
   "source": [
    "**Prerequisites**: This lab assumes: \n",
    "- you have already configured your FABRIC account following the provided instructions in [Fabric_Setup.md](../../Fabric_Setup.md), \n",
    "- you have reserved resources for yourself as instructed in [2-pre-lab1.ipynb](./2-pre-lab1.ipynb),\n",
    "- and that you have reviewed the background behind TCP congestion control protocols in [1-congestion-control-bg.md](./1-congestion-control-bg.md).\n",
    "\n",
    "In this notebook you will be using the reserved resources to execute some experiments related to TCP congestion control. For this, you will:\n",
    "-   Run the experiments on FABRIC resources\n",
    "-   Retrieve files saved on FABRIC hosts\n",
    "-   Visualize the data retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33b98f-7511-4e15-9623-97de2c76c343",
   "metadata": {},
   "source": [
    "# Log into resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a2dbb",
   "metadata": {},
   "source": [
    "In [2-pre-lab1.ipynb](./2-pre-lab1.ipynb), you ran the cells under \"Log into resources\" to get the SSH commands that you need to use to access the hosts on FABRIC. You should use those commands to open up terminal windows on Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e55322-e9ca-4293-9564-b52e3fe1e37e",
   "metadata": {},
   "source": [
    "To reiterate, you can do that as follows:\n",
    "\n",
    "-   in Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   copy an SSH command from the table, and paste it into the terminal. (Note that each SSH command is a single line, even if the display wraps the text to a second line! When you copy and paste it, paste it all together.)\n",
    "\n",
    "You can repeat this process (open several terminals) to start a session on each resource. Each terminal session will have a tab in the Jupyter environment, so that you can easily switch between them.\n",
    "\n",
    "Make sure to have at least one terminal open for each host and have the SSH commands accessible to open up more terminal windows as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a85d24",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bc364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc21d1-0217-4c35-b567-ec4e36538768",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "We will be running some experiments on FABRIC that show the basic behavior of TCP congestion control. You'll see the classic \"sawtooth\" pattern in a TCP flow's congestion window, and you'll see how a TCP flow responds to congestion indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1461c",
   "metadata": {},
   "source": [
    "We will send TCP flows between the two hosts, and generate data about the congestion window and slow start threshold over time.\n",
    "\n",
    "We reserved a topology including two end hosts, and a router between them in [2-pre-lab1.ipynb](./2-pre-lab1.ipynb). The router will buffer traffic between the sender and the receiver. If the buffer in the router becomes full, it will drop packets, triggering TCP congestion control behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0162dd",
   "metadata": {},
   "source": [
    "## Exercise 1: Using `ss` to observe TCP socket statistics\n",
    "\n",
    "The parameters of the TCP congestion control algorithm, such as congestion window and slow start threshold, are _not_ included in any packet header, since these are used only on the sender side. Therefore, we can't see the details of the congestion control by monitoring packets in `tcpdump` or other packet capture tools.\n",
    "\n",
    "Instead, we will use `ss`, a linux utility used to monitor local sockets and display socket statistics. In this section, we'll see what the `ss` output looks like, and what useful information it includes.\n",
    "\n",
    "On the \"juliet\" host, set up an `iperf3` server with\n",
    "\n",
    "```\n",
    "iperf3 -s  -1\n",
    "```\n",
    "\n",
    "On the \"romeo\" host, initiate a connection to the `iperf3` server on \"juliet\" and send data using TCP Reno congestion control, for 60 seconds, with\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -t 60 -C reno\n",
    "```\n",
    "\n",
    "While `iperf3` is still sending traffic, open another SSH session on \"romeo\" and run\n",
    "\n",
    "```\n",
    "ss -ein dst 10.10.2.100\n",
    "```\n",
    "\n",
    "Here, we use `ss` with some key arguments:\n",
    "\n",
    "*   `-e` to show detailed socket information\n",
    "*   `-i` to show internal TCP information. This information is known only to the operating system at the sender side; it is not sent over the network or otherwise shared with the receiver.\n",
    "*   `-n` specifies that it should not try to resolve names, but should show numeric values (i.e. IP addresses and not hostnames)\n",
    "*   `dst 10.10.2.100` is a filter that says it should only show sockets with the remote address 10.10.2.100 (the address of \"juliet\")\n",
    "\n",
    "You can learn more about `ss` arguments with `man ss` or by visiting the online [man page](https://linux.die.net/man/8/ss?ref=witestlab.poly.edu).\n",
    "\n",
    "The output of this command will look something like this, although the exact details will vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Netid     State      Recv-Q      Send-Q            Local Address:Port             Peer Address:Port                                                                                                               \n",
    "tcp       ESTAB      0           343176              10.10.1.100:49112             10.10.2.100:5201       timer:(on,1.204ms,0) uid:20001 ino:386735 sk:3b <->\n",
    "     ts sack reno wscale:7,7 rto:1212 rtt:833.978/7.108 mss:1448 pmtu:1500 rcvmss:536 advmss:1448 cwnd:66 ssthresh:35 bytes_acked:589374 segs_out:557 segs_in:273 data_segs_out:555 send 916.7Kbps lastsnd:8 lastrcv:5016 lastack:8 pacing_rate 1.2Mbps delivery_rate 942.8Kbps busy:4972ms rwnd_limited:96ms(1.9%) unacked:71 retrans:2/76 lost:2 sacked:5 rcv_space:14480 rcv_ssthresh:64088 notsent:240368 minrtt:0.483\n",
    "\n",
    "tcp       ESTAB      0           0                   10.10.1.100:49110             10.10.2.100:5201       uid:20001 ino:386734 sk:3c <->\n",
    "     ts sack cubic wscale:7,7 rto:208 rtt:5.598/9.458 ato:40 mss:1448 pmtu:1500 rcvmss:536 advmss:1448 cwnd:10 bytes_acked:144 bytes_received:4 segs_out:8 segs_in:7 data_segs_out:3 data_segs_in:3 send 20.7Mbps lastsnd:5020 lastrcv:4972 lastack:4972 pacing_rate 41.4Mbps delivery_rate 9.2Mbps busy:48ms rcv_space:14480 rcv_ssthresh:64088 minrtt:0.723\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67537c",
   "metadata": {},
   "source": [
    "We have two TCP sockets with the specified destination address. One is a socket used to share `iperf3` control information with the receiver. The other is a socket that carries the actual data between the sender and receiver. You can tell which one is which by looking at the `data_segs_out` value - the control flow only sends a few data segments, but the data flow will transfer hundreds or thousands of segments. In this case, the first lines in the `ss` output show the data flow, and the last lines show the control flow.\n",
    "\n",
    "Also note that the data flow uses TCP Reno, as we specified in the `iperf3` arguments. The control flow uses whatever congestion control is the system default - here, it's TCP Cubic.\n",
    "\n",
    "After running the command on your end, **paste the output in the worksheet**.\n",
    "\n",
    "In the `ss` output for the data flow, see if you can find the following and **note them down in the worksheet**:\n",
    "\n",
    "*   the current CWND of this flow. This is shown in units of MSS.\n",
    "*   the slow start threshold of this flow. This is shown in units of MSS. The slow start threshold field, `ssthresh`, will only appear in the `ss` output once the flow has entered the congestion avoidance phase.\n",
    "*   the number of retransmitted segments. This will only appear in the `ss` output once there has been a retransmission in the lifetime of the flow. If it appears in the output, it will show two values: the number of currently unacknowledged retransmitted segments, and the total (cumulative) number of retransmissions for the flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27af77",
   "metadata": {},
   "source": [
    "## Exercise 2: Observing TCP Flows with TCP Reno\n",
    "Next, we will generate some TCP flows between the two end hosts, and use it to observe the behavior of the TCP congestion control algorithm.\n",
    "\n",
    "While the TCP flows are running, we will also run a script that repeatedly runs `ss` and redirects the output to a file. When you press Ctrl+C, it will stop running the `ss` command and process the raw output into a format that is more convenient for data analysis and visualization.\n",
    "\n",
    "Download this script on the \"romeo\" host with\n",
    "\n",
    "```\n",
    "wget -O ss-output.sh https://raw.githubusercontent.com/ffund/tcp-ip-essentials/cloudlab/scripts/ss-output.sh\n",
    "```\n",
    "\n",
    "On the \"juliet\" host, run\n",
    "\n",
    "```\n",
    "iperf3 -s -1\n",
    "```\n",
    "\n",
    "In a terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "bash ss-output.sh 10.10.2.100\n",
    "```\n",
    "\n",
    "In a second terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -P 3 -t 60 -C reno\n",
    "```\n",
    "\n",
    "Here\n",
    "\n",
    "*   `-t 60` says to run for 60 seconds\n",
    "*   `-c juliet` says to send traffic to the host named \"juliet\"\n",
    "*   `-P 3` says to send 3 parallel TCP flows\n",
    "*   `-C reno` says to use TCP Reno for the data flows\n",
    "\n",
    "While `iperf3` is running, you will see periodic updates in the `iperf3` window, and a continuous flow of socket statistics data in the `ss` window. After about a minute, you will see a final status report in the `iperf3` window, and the `iperf3` process will finish. Then, use Ctrl+C to stop the `ss` script in the other window. Pressing Ctrl+C once will cause the script to process the raw data, and then exit.\n",
    "\n",
    "If you run `ls` on the \"romeo\" host, you should see two files generated by the `ss` script:\n",
    "\n",
    "*   `sender-ss.txt` is the raw output - the complete output of the `ss` command each time it was executed by the script.\n",
    "*   `sender-ss.csv` is a processed output - the script parsed the raw output, for each line of output, it prints the following comma-separated columns, in order, for each row of output:\n",
    "*   Timestamp (in [Unix time](https://en.wikipedia.org/wiki/Unix_time?ref=witestlab.poly.edu) format)\n",
    "*   TCP sender, in IP:Port format. Each of the TCP flows in this experiment will use a different local port number, and the control flow will use a unique local port number as well. We'll use this field to distinguish the flows.\n",
    "*   Number of currently unacknowledged retransmissions for this flow.\n",
    "*   Cumulative number of retransmissions for this flow.\n",
    "*   Current CWND of this flow.\n",
    "*   Current slow start threshold of this flow.\n",
    "*   Current smoothed RTT of this flow in ms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1391ae",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa87077",
   "metadata": {},
   "source": [
    "Now that we have generated some data, we will transfer the `sender-ss.csv` file from the host to the Jupyter environment and visualize the results.\n",
    "Use the next cell to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_node(\"romeo\").download_file(os.path.join(os.getcwd() + \"/sender-ss.csv\"), \"sender-ss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffe466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sender-ss.csv\", names=['time', 'sender', 'retx_unacked', 'retx_cum', 'cwnd', 'ssthresh', 'rtt'])\n",
    "\n",
    "# exclude the \"control\" flow\n",
    "s = df.groupby('sender').size()\n",
    "df_filtered = df[df.groupby(\"sender\")['sender'].transform('size') > 100]\n",
    "\n",
    "senders = df_filtered.sender.unique()\n",
    "\n",
    "time_min = df_filtered.time.min()\n",
    "cwnd_max = 1.1*df_filtered.cwnd.max()\n",
    "dfs = [df_filtered[df_filtered.sender==senders[i]] for i in range(3)]\n",
    "\n",
    "fig, axs = plt.subplots(len(senders), sharex=True, figsize=(12,8))\n",
    "fig.suptitle('CWND over time')\n",
    "for i in range(len(senders)):\n",
    "    if i==len(senders)-1:\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['cwnd'], label=\"cwnd\")\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['ssthresh'], label=\"ssthresh\")\n",
    "        axs[i].set_ylim([0,cwnd_max])\n",
    "        axs[i].set_xlabel(\"Time (s)\");\n",
    "    else:\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['cwnd'])\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['ssthresh'])\n",
    "        axs[i].set_ylim([0,cwnd_max])\n",
    "\n",
    "\n",
    "plt.tight_layout();\n",
    "fig.legend(loc='upper right', ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117bfec",
   "metadata": {},
   "source": [
    "At the beginning of each flow, it operates in slow start mode, where the congestion window increases exponentially. When a congestion event occurs, as indicated by the receipt of multiple duplicate ACKs, the slow start threshold is set to half of the current CWND, and then the CWND is reduces to the slow start threshold.\n",
    "\n",
    "We'll often see packet losses occur at the same time in multiple flows sharing a bottleneck (as in the figure above), because when the buffer is full, new packets arriving from all flows are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9ba41",
   "metadata": {},
   "source": [
    "**Take a few minutes to do the following in the worksheet:**\n",
    "Quickly, annotate your plot to show:\n",
    "\n",
    "- Periods of \"Slow Start\"\n",
    "- Periods of \"Congestion Avoidance\"\n",
    "- Instances where multiple duplicate ACKs were received (which will trigger \"fast recovery\")\n",
    "- Instances of timeout (if any)\n",
    "\n",
    "Also, using your plot and/or experiment data, briefly explain how the behavior of TCP is different in the \"Slow Start\" and \"Congestion Avoidance\" phases. Also, using your plot, explain what happens to both the congestion window and the slow start threshold when multiple duplicate ACKs are received."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b678a9",
   "metadata": {},
   "source": [
    "## Exercise 3: Other Congestion Control Algorithms - TCP Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5d46d",
   "metadata": {},
   "source": [
    "In the decades since TCP Reno was first proposed, several other congestion control algorithms have been developed that offer improved performance in some circumstances.\n",
    "\n",
    "You can repeat this experiment with other congestion control variants by changing the value of the `-C` argument in `iperf3`.\n",
    "\n",
    "First, make sure to save the data from the previous exercise. When you run the experiment again (with a different control control algorithm), it will overwrite your previous data, so you want to have that safely stored somewhere else first.\n",
    "\n",
    "For example, you could run this experiment with TCP Cubic, which is the current default on Linux servers that power much of the Internet. The main difference between TCP Reno and TCP Cubic is the window increase function. While Reno uses the traditional linear increase (W=W+1), Cubic implements a binary search increase which can reach the available bandwidth much faster than Reno. You may read more about Cubic in the [TCP Cubic paper](https://www.cs.princeton.edu/courses/archive/fall16/cos561/papers/Cubic08.pdf?ref=witestlab.poly.edu).\n",
    "\n",
    "To run the experiment with TCP Cubic, you would repeat the steps in the Exercise 2 above, but with the `-C` argument in the `iperf3` command, i.e. do the following:\n",
    "\n",
    "On the \"juliet\" host, run\n",
    "```\n",
    "iperf3 -s -1\n",
    "```\n",
    "In a terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "bash ss-output.sh 10.10.2.100\n",
    "```\n",
    "\n",
    "In a second terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -P 3 -t 60 -C cubic\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The results, showing the experiment results for TCP CUBIC, will look something like this:\n",
    "\n",
    "![](https://witestlab.poly.edu/blog/content/images/2024/03/sender-ss-cubic-2.png)\n",
    "\n",
    "\n",
    "Notice that unlike Reno, the window size does not increase as a linear function of the time since the last congestion event! Instead, the window size is a cubic function of the time since the last congestion event.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963d21c",
   "metadata": {},
   "source": [
    "As before, we will transfer the `sender-ss.csv` file from the host to the Jupyter environment and visualize the results.\n",
    "The following cells are the exactly the same as in Exercise 1. You may use these cells for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_node(\"romeo\").download_file(os.path.join(os.getcwd() + \"/sender-ss.csv\"), \"sender-ss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d24217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sender-ss.csv\", names=['time', 'sender', 'retx_unacked', 'retx_cum', 'cwnd', 'ssthresh', 'rtt'])\n",
    "\n",
    "# exclude the \"control\" flow\n",
    "s = df.groupby('sender').size()\n",
    "df_filtered = df[df.groupby(\"sender\")['sender'].transform('size') > 100]\n",
    "\n",
    "senders = df_filtered.sender.unique()\n",
    "\n",
    "time_min = df_filtered.time.min()\n",
    "cwnd_max = 1.1*df_filtered.cwnd.max()\n",
    "dfs = [df_filtered[df_filtered.sender==senders[i]] for i in range(3)]\n",
    "\n",
    "fig, axs = plt.subplots(len(senders), sharex=True, figsize=(12,8))\n",
    "fig.suptitle('CWND over time')\n",
    "for i in range(len(senders)):\n",
    "    if i==len(senders)-1:\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['cwnd'], label=\"cwnd\")\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['ssthresh'], label=\"ssthresh\")\n",
    "        axs[i].set_ylim([0,cwnd_max])\n",
    "        axs[i].set_xlabel(\"Time (s)\");\n",
    "    else:\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['cwnd'])\n",
    "        axs[i].plot(dfs[i]['time']-time_min, dfs[i]['ssthresh'])\n",
    "        axs[i].set_ylim([0,cwnd_max])\n",
    "\n",
    "\n",
    "plt.tight_layout();\n",
    "fig.legend(loc='upper right', ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569073c5",
   "metadata": {},
   "source": [
    "**In your worksheet**, paste your figure and briefly comment on the differences as compared to the TCP Reno flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3b2d2",
   "metadata": {},
   "source": [
    "## Exercise 4: Low Delay Congestion Control - TCP Vegas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf601f",
   "metadata": {},
   "source": [
    "While TCP CUBIC and Reno are designed with the goal of high throughput, they tend to cause high queuing delays in the network, because they reduce their CWND only when they experience a packet loss, i.e. when the queue is full. A full queue means long queuing delays for packets that traverse the queue!\n",
    "\n",
    "Some congestion control variants use delay as a signal of congestion, and reduce their sending rate when the delay increases (indicating that the queue is becoming full). An early example is TCP Vegas. You can see this for yourself with a simple experiment to measure the queuing delay with a loss-based congestion control (like Reno or Cubic) and with a delay-based congestion control (Vegas).\n",
    "\n",
    "For this experiment we will use `iperf3` and `ping` at the same time - `iperf3` to generate a TCP flow, and `ping` to estimate the queuing delay induced by the TCP flow. Run\n",
    "\n",
    "*   on juliet: `iperf3 -s -1`\n",
    "*   on romeo terminal 1: `bash ss-output.sh 10.10.2.100`\n",
    "*   on romeo terminal 2: `iperf3 -c juliet -t 60 -C reno`\n",
    "*   on romeo terminal 3: `ping juliet -c 50`\n",
    "\n",
    "(the `ping` should both start and finish while the `iperf3` sender is still running). When it finishes, use Ctrl+C to stop the `ss-output` script. Make a note of the `iperf3` throughput and the round trip time estimated by `ping` during the TCP Reno flow and write this down in the worksheet.\n",
    "\n",
    "Plot the CWND and slow start threshold, along with the RTT of this flow, using the following Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56296c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sender-ss.csv\", names=['time', 'sender', 'retx_unacked', 'retx_cum', 'cwnd', 'ssthresh', 'rtt'])\n",
    "\n",
    "# exclude the \"control\" flow\n",
    "s = df.groupby('sender').size()\n",
    "df_filtered = df[df.groupby(\"sender\")['sender'].transform('size') > 100]\n",
    "time_min = df_filtered.time.min()\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize=(8,6))\n",
    "\n",
    "axs[0].plot(df_filtered['time']-time_min, df_filtered['cwnd'], label=\"cwnd\")\n",
    "axs[0].plot(df_filtered['time']-time_min, df_filtered['ssthresh'], label=\"ssthresh\")\n",
    "axs[0].set_ylim([0,150])\n",
    "\n",
    "axs[1].plot(df_filtered['time']-time_min, df_filtered['rtt'], label=\"rtt\", color='purple')\n",
    "axs[1].set_ylim([0, 1000])\n",
    "axs[1].set_xlabel(\"Time (s)\");\n",
    "\n",
    "plt.tight_layout();\n",
    "fig.legend(loc='upper right', ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4f100",
   "metadata": {},
   "source": [
    "**Paste this figure in your worksheet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b80c06",
   "metadata": {},
   "source": [
    "Then, repeat with Vegas, the delay-based congestion control algorithm. On romeo, run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b0e1a7",
   "metadata": {},
   "source": [
    "```\n",
    "sudo modprobe tcp_vegas\n",
    "sudo sysctl -w net.ipv4.tcp_allowed_congestion_control=\"reno cubic vegas\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c760761",
   "metadata": {},
   "source": [
    "then, run\n",
    "\n",
    "*   on juliet: `iperf3 -s -1`\n",
    "*   on romeo terminal 1: `bash ss-output.sh 10.10.2.100`\n",
    "*   on romeo terminal 2: `iperf3 -c juliet -t 60 -C vegas`\n",
    "*   on romeo terminal 3: `ping juliet -c 50`\n",
    "\n",
    "When it finishes, use Ctrl+C to stop the `ss-output` script. Make a note of the `iperf3` throughput and the round trip time estimated by `ping` during the TCP Vegas flow.\n",
    "\n",
    "One problem with TCP Vegas is that it does not work well when it shares a bottleneck link with a TCP Reno flow (or other loss-based flow). To see how this works, we will send two TCP flows through the bottleneck router: one TCP Reno flow, and one TCP Vegas flow.\n",
    "\n",
    "We will need two `iperf3` servers running on juliet, on two different ports. In one terminal on juliet, run\n",
    "\n",
    "```\n",
    "iperf3 -s -1\n",
    "```\n",
    "\n",
    "to start an `iperf3` server on the default port 5201, and in a second terminal on juliet, run\n",
    "\n",
    "```\n",
    "iperf3 -s -1 -p 5301\n",
    "```\n",
    "\n",
    "to start an `iperf3` server on port 5301.\n",
    "\n",
    "You'll need two terminal windows on romeo. In one of them, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -t 60 -C vegas\n",
    "```\n",
    "\n",
    "and a few seconds afterwards, in the second, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -t 60 -C reno -p 5301\n",
    "```\n",
    "\n",
    "**Make a note of the throughput** reported by `iperf3` for each flow and note it down in the worksheet.\n",
    "\n",
    "Once you are done with this exercise, take a moment to think about the \"fairness\" between the users if they are using different protocols. **Note down your thoughts in the worksheet**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b43093",
   "metadata": {},
   "source": [
    "## Exercise 5: TCP BBR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7741a",
   "metadata": {},
   "source": [
    "A more recent congestion control proposed by Google, called TCP BBR, tries to maximize throughput and at the same time minimize queuing delay in the network. You can read more about it in the [TCP BBR paper](https://research.google/pubs/pub45646/?ref=witestlab.poly.edu).\n",
    "\n",
    "To use the BBR congestion control for your experiment, on romeo, run\n",
    "\n",
    "```\n",
    "sudo modprobe tcp_bbr\n",
    "sudo sysctl -w net.ipv4.tcp_allowed_congestion_control=\"reno cubic vegas bbr\"\n",
    "```\n",
    "\n",
    "This will load the Linux kernel module for TCP BBR.\n",
    "\n",
    "Then, repeat the steps in Exercise 2 and 3, but with the `-C` argument specifying `bbr` in the `iperf3` command, i.e. do the following:\n",
    "\n",
    "On the \"juliet\" host, run\n",
    "```\n",
    "iperf3 -s -1\n",
    "```\n",
    "In a terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "bash ss-output.sh 10.10.2.100\n",
    "```\n",
    "\n",
    "In a second terminal on the \"romeo\" host, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -P 3 -t 60 -C bbr\n",
    "\n",
    "```\n",
    "\n",
    "BBR doesn't use a slow start threshold, so you won't be able to use the same data visualization script (which assumes that there will be an `ssthresh` field in the data), but you can create a similar plot on your own later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca103a",
   "metadata": {},
   "source": [
    "The results will look something like this:\n",
    "\n",
    "![](https://witestlab.poly.edu/blog/content/images/2020/10/sender-ss-bbr.svg)\n",
    "\n",
    "Note that BBR overall maintains a lower CWND than Cubic or Reno, because it wants to minimize queue occupancy. But you'll see in the `iperf3` output that it still achieves a similar throughput (about 1Mbps total shared between the 3 flows). Also, if you look at the raw `ss` data for the BBR and the Reno/Cubic flows, you'll note that the BBR flows see a much lower RTT, since they do not fill the queue.\t **In the worksheet**, briefly comment about your observation regarding this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4f028",
   "metadata": {},
   "source": [
    "## Exercise 6: Explicit congestion notification (ECN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdad5c0",
   "metadata": {},
   "source": [
    "Finally, we'll try an experiment with explicit congestion notification. Explicit congestion notification (ECN) is a feature that allows routers to explicitly signal to a TCP sender when there is congestion. This allows the sender to reduce its congestion window _before_ the router is forced to drop packets, reducing retransmissions. It can also help the router maintain a minimal queue, which reduces queuing delay.\n",
    "\n",
    "ECN involves both layer 2 and layer 3, and it requires support from both transport layer endpoints (sender _and_ receiver) and routers along the path traversed by the packets.\n",
    "\n",
    "We will use ECN together with active queue management, which monitors the queuing delay. At the router, configure a queue in both directions that will mark packets when the queuing delay exceeds 10ms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23512f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "iface_0=$(ip route get 10.10.1.100 | grep -oP \"(?<=dev )[^ ]+\")\n",
    "sudo tc qdisc del dev $iface_0 root  \n",
    "sudo tc qdisc add dev $iface_0 root handle 1: htb default 3  \n",
    "sudo tc class add dev $iface_0 parent 1: classid 1:3 htb rate 1Mbit  \n",
    "sudo tc qdisc add dev $iface_0 parent 1:3 handle 3:  codel limit 100 target 10ms ecn\n",
    "\n",
    "iface_1=$(ip route get 10.10.2.100 | grep -oP \"(?<=dev )[^ ]+\")\n",
    "sudo tc qdisc del dev $iface_1 root  \n",
    "sudo tc qdisc add dev $iface_1 root handle 1: htb default 3  \n",
    "sudo tc class add dev $iface_1 parent 1: classid 1:3 htb rate 1Mbit  \n",
    "sudo tc qdisc add dev $iface_1 parent 1:3 handle 3:  codel limit 100 target 10ms ecn\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08cf21d",
   "metadata": {},
   "source": [
    "On romeo and juliet, enable ECN in TCP by running\n",
    "\n",
    "```\n",
    "sudo sysctl -w net.ipv4.tcp_ecn=1   \n",
    "```\n",
    "\n",
    "Next, we'll prepare to capture the TCP flow. On both end hosts, romeo _and_ juliet, run:\n",
    "\n",
    "```\n",
    "sudo tcpdump -s 80 -i $(ip route get 10.10.1.1 | grep -oP \"(?<=dev )[^ ]+\") 'tcp' -w $(hostname -s)-tcp-ecn.pcap\n",
    "```\n",
    "\n",
    "ECN uses two flags in the TCP header: the ECN Echo (ECE) flag, and the Congestion Window Reduced (CWR) flag. It also uses two ECN bits in the DiffServ field of the IP header. Here is how these header fields are used:\n",
    "\n",
    "- During the connection establishment phase of TCP, both endpoints indicate to the other that they support ECN. First, one host sends an ECN-setup SYN packet: it sets the ECE and CWR flags in the TCP header of the SYN. Then, the other host response with an ECN-setup SYN-ACK packet: it sets the ECE flag (but not the CWR flag) in the TCP header of the SYN-ACK.\n",
    "\n",
    "- In any subsequent packets that carry data (not pure ACKs!), the sender will set the two ECN bits in the IP header to either 10 or 01. Either of these flag values will indicate to the routers along the path that this data packet uses an ECN-capable transport.\n",
    "\n",
    "- If the router wants to signal to the TCP sender that there is congestion - for example, if the queue at the router is starting to fill up - then it sets the two ECN bits in the IP header to 11 before forwarding the packet to the destination. This is a \"Congestion Experienced\" signal.\n",
    "\n",
    "- If the receiver gets a data packet with the CE signal (the ECN bits in the IP header are set to 11), the receiver will set the ECN-Echo (ECE) flag in the TCP header _of the ACK_ for that packet.\n",
    "\n",
    "- When the sender gets the ACK with the ECE flag set, it will reduce its CWND. Then it will set the Congestion Window Reduced (CWR) flag in the TCP header of the next packet.\n",
    "\n",
    "With the `tcpdump` running, we can now run the experiment. In a second terminal on juliet, run\n",
    "\n",
    "```\n",
    "iperf3 -s -1\n",
    "```\n",
    "\n",
    "In a second terminal on romeo, run\n",
    "\n",
    "```\n",
    "iperf3 -c juliet -t 60 -C reno\n",
    "```\n",
    "\n",
    "and finally, in a third terminal on romeo, run\n",
    "\n",
    "```\n",
    "ping -c 50 juliet\n",
    "```\n",
    "\n",
    "When the experiment finishes, **compare the delay performance of Reno with ECN (this experiment) to your previous experiment showing the delay performance without ECN**.\n",
    "\n",
    "Also, you may transfer the packet captures to your laptop with `scp`, and look for the ECN-related fields in the IP header and TCP header, during connection establishment and during data transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d48277-687d-4b0a-9580-7b387ba48326",
   "metadata": {},
   "source": [
    "### Transfer .pcap files from a FABRIC host\n",
    "\n",
    "After you have executed the TCP ECN exercise, you can retrieve the `romeo-tcp-ecn.pcap` and `juliet-tcp-ecn.pcap` files from the FABRIC hosts with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3cee3-d82a-441a-90f8-048f7ef9a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_node(\"romeo\").download_file(\"/home/fabric/work/romeo-tcp-ecn.pcap\", \"romeo-tcp-ecn.pcap\")\n",
    "slice.get_node(\"juliet\").download_file(\"/home/fabric/work/juliet-tcp-ecn.pcap\", \"juliet-tcp-ecn.pcap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75414808-1a13-491c-abec-bfaad5522e8e",
   "metadata": {},
   "source": [
    "Then in the Jupyter environment, click on the folder icon in the file browser on the left to make sure that you are located in your “Jupyter home” directory.\n",
    "\n",
    "You should see the above .pcap files appear in the Jupyter file browser on the left. You can now download this file from the Jupyter environment to your own laptop to analyze them in Wireshark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14d0e3",
   "metadata": {},
   "source": [
    "# Delete your slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7c9f5",
   "metadata": {},
   "source": [
    "Once you are done with using the resources, you should delete your slice. You can do so by following the instructions in [4-post-lab1.ipynb](./4-post-lab1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b6c6a",
   "metadata": {},
   "source": [
    "### Acknowledgment\n",
    "Based on [Wireless Implementation Testbed Lab](https://witestlab.poly.edu/blog/)'s experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
